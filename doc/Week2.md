# 第二周项目报告 特征工程与基本模型的探索

## 1. 特征工程
### 1.1 新增加的特征
因为考虑到LR模型对连续数值型的优势，而对于类别型特征不是特别友好，
而LabelEncoder会丢失掉一些信息，
OneHotEncoder又会增加非常多的维度，这都是我们不希望发生的
所以，我在做数据探索的时候，发现后验概率体现了与Click关系非常大的值，
就突发奇想，用点击率在每个特征的后验概率作为编码值，取代原来的特征值

优点：连续型数值型特征，在LR模型下，也可以很方便的做Polynomial的特征组合
缺点：在一个下采样率为0.05的小数据集上耗时非常多，目测有1个小时
结果：在训练集的CV上，最优情况评分为0.309158964
### 1.2 尝试多项式
在1.1的基础上，引入多项式
- degree = 2 
10w data set: cv=3
LR scores: 
{1: array([[-0.34277606],
       [-0.28644995],
       [-0.31141963]])}
mean = 0.313548546666667
- degree = 3


## 2. LR模型的训练与探索
LR模型主要训练两个超参数： C 和 Penalty。
选用了GridsearchCV，初始参数列表为：
penaltys = ['l1','l2']
Cs = [0.001, 0.01, 0.1]
最好的参数组合以及评分是：
0.31188178822656837
{'C': 0.01, 'penalty': 'l1'}

在10w小数据集上：Cs=[0.01, 0.001]
[LibLinear]LR scores: {1: array([[-0.33134524, -0.3710681 ],
       [-0.33647852, -0.37531413],
       [-0.28313994, -0.34936791],
       [-0.32164976, -0.34027636],
       [-0.28756946, -0.34457516]])}
C1_mean = 0.312036584 
C2_mean = 0.356120332

After StandardScaler:
[LibLinear]LR scores: {1: array([[-0.32873602, -0.33194471],
       [-0.33599484, -0.34008852],
       [-0.27917869, -0.28751184],
       [-0.36950372, -0.33743407],
       [-0.30631008, -0.28564939]])}
C1_mean = 0.32394467 
C2_mean = 0.316525706

MinMaxScale:
[LibLinear]LR scores: {1: array([[-0.33204208, -0.36633531],
       [-0.336775  , -0.37410594],
       [-0.28374088, -0.3402616 ],
       [-0.34492496, -0.33964801],
       [-0.28889752, -0.34543589]])}
C1_mean = 0.317276088 
C2_mean = 0.35315735

决定不对特征进行Scale处理

在50w的数据子集上跑结果：
[LibLinear]LR scores: {1: array([[-0.32028113, -0.32205696],
       [-0.26406824, -0.28154869],
       [-0.30404612, -0.30342691],
       [-0.30900443, -0.3250579 ],
       [-0.3483949 , -0.3533593 ]])}
C1_mean = 0.309158964 
C2_mean = 0.35315735

在Kaggle上最终得分：private：0.4634562 public 0.4654680
